{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Kaggle Titanic Machine Learning\n- source of competition: https://www.kaggle.com/c/titanic\n- Data Dictionary: https://www.kaggle.com/c/titanic/data\n- useful link for saving to GitHub: https://www.kaggle.com/questions-and-answers/72234"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Importing libraries\n%matplotlib inline\nimport numpy as np \nimport pandas as pd \nimport pandas_profiling\n\n# Setting Random Seed For Reproducibility\nimport random\nrandom.seed(123)\n\n# Displaying Max rows\npd.set_option('display.max_rows', 1000)\npd.set_option('display.max_columns', 100)\n\n# Listing Files\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":2,"outputs":[{"output_type":"stream","text":"/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/gender_submission.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/titanic/train.csv')\ndf_test = pd.read_csv('/kaggle/input/titanic/test.csv') # for final evaluation/submission only","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":5,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Data Wrangling/Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating train/val/test split prior to transformations (avoid data leakage)\n\nX = df_train.drop(['Survived'],axis = 1)\ny = df_train.Survived\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.15, random_state = 3) # test set 15% train\nX_train, X_val, y_train, y_val   = train_test_split(X_train, y_train, test_size = 0.15, random_state = 3) #validation set 15% train","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in [X_train,X_test,X_val]:\n    print(i.shape)","execution_count":7,"outputs":[{"output_type":"stream","text":"(643, 11)\n(134, 11)\n(114, 11)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis\n\nGeneral thoughts based on the profile below\n- PassengerId - removing due to ID variable\n- Missing values: Age, Cabin, Fare, Embarked\n- Correlations in Fare-Class-Age"},{"metadata":{"trusted":true},"cell_type":"code","source":"#combining the train feature/target data for EDA/Data Wrangling\n\ndf_train_split = pd.concat([X_train, y_train], axis = 1)\ndf_train_split.head(2)","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"     PassengerId  Pclass               Name     Sex   Age  SibSp  Parch  \\\n387          388       2   Buss, Miss. Kate  female  36.0      0      0   \n531          532       3  Toufik, Mr. Nakli    male   NaN      0      0   \n\n    Ticket     Fare Cabin Embarked  Survived  \n387  27849  13.0000   NaN        S         1  \n531   2641   7.2292   NaN        C         0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>387</th>\n      <td>388</td>\n      <td>2</td>\n      <td>Buss, Miss. Kate</td>\n      <td>female</td>\n      <td>36.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>27849</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>531</th>\n      <td>532</td>\n      <td>3</td>\n      <td>Toufik, Mr. Nakli</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2641</td>\n      <td>7.2292</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#making use of the profile package for EDA plots/stats/...\n\nprofile = pandas_profiling.ProfileReport(df_train_split, title = \"EDA Profile Train Data Report\")","execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='variables', max=13.0, style=ProgressStyle(description_wid…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2212f13e47914a238de7deb66e22977e"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='correlations', max=6.0, style=ProgressStyle(description_w…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"329857e2b0f24b9a86cc5564cf38a9fc"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='interactions [continuous]', max=36.0, style=ProgressStyle…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba4710bd6a1745ff98f32d54463b4a73"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='table', max=1.0, style=ProgressStyle(description_width='i…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a32dfa87345444ba9aab8765cc4588a"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='missing', max=4.0, style=ProgressStyle(description_width=…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b4e4bec718d4d5ca80903be404e7342"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='warnings', max=3.0, style=ProgressStyle(description_width…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c6e40afb37e4224a959fb757a648b06"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='package', max=1.0, style=ProgressStyle(description_width=…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38ea21dfa99349c6a9df4e48fb06ac4c"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='build report structure', max=1.0, style=ProgressStyle(des…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"766660122b824d50a459dcc81c95d8f3"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"profile.to_widgets()","execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Tab(children=(Tab(children=(GridBox(children=(VBox(children=(GridspecLayout(children=(HTML(value='Number of va…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8cce1b878654c028a593dfb8da01f22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Report generated with <a href=\"https://github.com/pandas-profiling/pandas-profiling\">pandas-profiling</a>."},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Data Wrangling and Feature Engineering\n- only on training dataset, will use a pipeline for val/test and final submission test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Missing Values Handling\nprint(df_train_split.Embarked.value_counts())\n\n#Embarked only 1 missing, fill with most common of S, C, Q (will be S)\ndf_train_split.Embarked = df_train_split.Embarked.fillna(df_train_split.Embarked.value_counts().index[0]) #using value_counts top record","execution_count":11,"outputs":[{"output_type":"stream","text":"S    475\nC    118\nQ     49\nName: Embarked, dtype: int64\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping passenger id (is an id)\ndf_train_split.drop(['PassengerId'], axis = 1, inplace = True)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\nohe = OneHotEncoder(categories='auto')\nfeature_array = ohe.fit_transform(df_train_split[['Parch','Pclass','Sex','SibSp','Embarked']]).toarray()\n#feature_labels = ohe.categories_","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = pd.DataFrame(feature_array, columns=ohe.get_feature_names())\nprint(features.shape)\nfeatures.head()","execution_count":14,"outputs":[{"output_type":"stream","text":"(643, 22)\n","name":"stdout"},{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"   x0_0  x0_1  x0_2  x0_3  x0_4  x0_5  x0_6  x1_1  x1_2  x1_3  x2_female  \\\n0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0        1.0   \n1   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0        0.0   \n2   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0        0.0   \n3   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0        0.0   \n4   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0        1.0   \n\n   x2_male  x3_0  x3_1  x3_2  x3_3  x3_4  x3_5  x3_8  x4_C  x4_Q  x4_S  \n0      0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  \n1      1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  \n2      1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   1.0  \n3      1.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  \n4      0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x0_0</th>\n      <th>x0_1</th>\n      <th>x0_2</th>\n      <th>x0_3</th>\n      <th>x0_4</th>\n      <th>x0_5</th>\n      <th>x0_6</th>\n      <th>x1_1</th>\n      <th>x1_2</th>\n      <th>x1_3</th>\n      <th>x2_female</th>\n      <th>x2_male</th>\n      <th>x3_0</th>\n      <th>x3_1</th>\n      <th>x3_2</th>\n      <th>x3_3</th>\n      <th>x3_4</th>\n      <th>x3_5</th>\n      <th>x3_8</th>\n      <th>x4_C</th>\n      <th>x4_Q</th>\n      <th>x4_S</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_split = df_train_split.drop(['Parch','Pclass','Sex','SibSp','Embarked'], axis = 1)\n","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train_split.shape)\ndf_train_split.head()","execution_count":16,"outputs":[{"output_type":"stream","text":"(643, 6)\n","name":"stdout"},{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"                                                  Name   Age   Ticket  \\\n387                                   Buss, Miss. Kate  36.0    27849   \n531                                  Toufik, Mr. Nakli   NaN     2641   \n480                     Goodwin, Master. Harold Victor   9.0  CA 2144   \n217                       Jacobsohn, Mr. Sidney Samuel  42.0   243847   \n799  Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...  30.0   345773   \n\n        Fare Cabin  Survived  \n387  13.0000   NaN         1  \n531   7.2292   NaN         0  \n480  46.9000   NaN         0  \n217  27.0000   NaN         0  \n799  24.1500   NaN         0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Age</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>387</th>\n      <td>Buss, Miss. Kate</td>\n      <td>36.0</td>\n      <td>27849</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>531</th>\n      <td>Toufik, Mr. Nakli</td>\n      <td>NaN</td>\n      <td>2641</td>\n      <td>7.2292</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>480</th>\n      <td>Goodwin, Master. Harold Victor</td>\n      <td>9.0</td>\n      <td>CA 2144</td>\n      <td>46.9000</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>217</th>\n      <td>Jacobsohn, Mr. Sidney Samuel</td>\n      <td>42.0</td>\n      <td>243847</td>\n      <td>27.0000</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>799</th>\n      <td>Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...</td>\n      <td>30.0</td>\n      <td>345773</td>\n      <td>24.1500</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_split = pd.concat([df_train_split.reset_index(drop=True),features.reset_index(drop=True)], axis = 1)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_split.shape\ndf_train_split.head()","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"                                                Name   Age   Ticket     Fare  \\\n0                                   Buss, Miss. Kate  36.0    27849  13.0000   \n1                                  Toufik, Mr. Nakli   NaN     2641   7.2292   \n2                     Goodwin, Master. Harold Victor   9.0  CA 2144  46.9000   \n3                       Jacobsohn, Mr. Sidney Samuel  42.0   243847  27.0000   \n4  Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...  30.0   345773  24.1500   \n\n  Cabin  Survived  x0_0  x0_1  x0_2  x0_3  x0_4  x0_5  x0_6  x1_1  x1_2  x1_3  \\\n0   NaN         1   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   \n1   NaN         0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   \n2   NaN         0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   \n3   NaN         0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   \n4   NaN         0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   \n\n   x2_female  x2_male  x3_0  x3_1  x3_2  x3_3  x3_4  x3_5  x3_8  x4_C  x4_Q  \\\n0        1.0      0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n1        0.0      1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   \n2        0.0      1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   \n3        0.0      1.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n4        1.0      0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n\n   x4_S  \n0   1.0  \n1   0.0  \n2   1.0  \n3   1.0  \n4   1.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Age</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Survived</th>\n      <th>x0_0</th>\n      <th>x0_1</th>\n      <th>x0_2</th>\n      <th>x0_3</th>\n      <th>x0_4</th>\n      <th>x0_5</th>\n      <th>x0_6</th>\n      <th>x1_1</th>\n      <th>x1_2</th>\n      <th>x1_3</th>\n      <th>x2_female</th>\n      <th>x2_male</th>\n      <th>x3_0</th>\n      <th>x3_1</th>\n      <th>x3_2</th>\n      <th>x3_3</th>\n      <th>x3_4</th>\n      <th>x3_5</th>\n      <th>x3_8</th>\n      <th>x4_C</th>\n      <th>x4_Q</th>\n      <th>x4_S</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Buss, Miss. Kate</td>\n      <td>36.0</td>\n      <td>27849</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Toufik, Mr. Nakli</td>\n      <td>NaN</td>\n      <td>2641</td>\n      <td>7.2292</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Goodwin, Master. Harold Victor</td>\n      <td>9.0</td>\n      <td>CA 2144</td>\n      <td>46.9000</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Jacobsohn, Mr. Sidney Samuel</td>\n      <td>42.0</td>\n      <td>243847</td>\n      <td>27.0000</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...</td>\n      <td>30.0</td>\n      <td>345773</td>\n      <td>24.1500</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_split.head()","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"                                                Name   Age   Ticket     Fare  \\\n0                                   Buss, Miss. Kate  36.0    27849  13.0000   \n1                                  Toufik, Mr. Nakli   NaN     2641   7.2292   \n2                     Goodwin, Master. Harold Victor   9.0  CA 2144  46.9000   \n3                       Jacobsohn, Mr. Sidney Samuel  42.0   243847  27.0000   \n4  Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...  30.0   345773  24.1500   \n\n  Cabin  Survived  x0_0  x0_1  x0_2  x0_3  x0_4  x0_5  x0_6  x1_1  x1_2  x1_3  \\\n0   NaN         1   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   \n1   NaN         0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   \n2   NaN         0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   \n3   NaN         0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   \n4   NaN         0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   \n\n   x2_female  x2_male  x3_0  x3_1  x3_2  x3_3  x3_4  x3_5  x3_8  x4_C  x4_Q  \\\n0        1.0      0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n1        0.0      1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   \n2        0.0      1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   \n3        0.0      1.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n4        1.0      0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n\n   x4_S  \n0   1.0  \n1   0.0  \n2   1.0  \n3   1.0  \n4   1.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Age</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Survived</th>\n      <th>x0_0</th>\n      <th>x0_1</th>\n      <th>x0_2</th>\n      <th>x0_3</th>\n      <th>x0_4</th>\n      <th>x0_5</th>\n      <th>x0_6</th>\n      <th>x1_1</th>\n      <th>x1_2</th>\n      <th>x1_3</th>\n      <th>x2_female</th>\n      <th>x2_male</th>\n      <th>x3_0</th>\n      <th>x3_1</th>\n      <th>x3_2</th>\n      <th>x3_3</th>\n      <th>x3_4</th>\n      <th>x3_5</th>\n      <th>x3_8</th>\n      <th>x4_C</th>\n      <th>x4_Q</th>\n      <th>x4_S</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Buss, Miss. Kate</td>\n      <td>36.0</td>\n      <td>27849</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Toufik, Mr. Nakli</td>\n      <td>NaN</td>\n      <td>2641</td>\n      <td>7.2292</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Goodwin, Master. Harold Victor</td>\n      <td>9.0</td>\n      <td>CA 2144</td>\n      <td>46.9000</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Jacobsohn, Mr. Sidney Samuel</td>\n      <td>42.0</td>\n      <td>243847</td>\n      <td>27.0000</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...</td>\n      <td>30.0</td>\n      <td>345773</td>\n      <td>24.1500</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_split.shape","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"(643, 28)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Encoding categorical features (will be used to impute Age/Cabin missing values as possible)\n\n# df_train_split = pd.get_dummies(df_train_split, columns=['Parch','Pclass','Sex','SibSp','Embarked'])\n# df_train_split","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encoding the Age Missing Values that are 'S' with the training data median Age \nmedian_age_train = df_train_split.Age.median()\ndf_train_split['Age'] = df_train_split['Age'].apply(lambda x : median_age_train if pd.isnull(x) else x)\ndf_train_split.Age.isna().sum()","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"0"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Cabin Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"#INPROGRESS #Missing Values Cabin - taking the initial value\ndf_train_split.Cabin = df_train_split[['Cabin']].fillna(value= 'Z')\ndf_train_split['Cabin_augment'] = df_train_split.Cabin.apply(lambda x : x[0]) # augmenting dataset, only want the first letter (numbers not matter)\ndf_train_split.Cabin_augment.value_counts()","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"Z    491\nC     44\nB     33\nD     26\nE     24\nA     12\nF     11\nT      1\nG      1\nName: Cabin_augment, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_split[['Cabin_augment','Fare']].groupby(['Cabin_augment']).mean().round(2)","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"                 Fare\nCabin_augment        \nA               39.35\nB              118.79\nC               91.22\nD               54.26\nE               44.00\nF               20.22\nG               16.70\nT               35.50\nZ               18.96","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Fare</th>\n    </tr>\n    <tr>\n      <th>Cabin_augment</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>A</th>\n      <td>39.35</td>\n    </tr>\n    <tr>\n      <th>B</th>\n      <td>118.79</td>\n    </tr>\n    <tr>\n      <th>C</th>\n      <td>91.22</td>\n    </tr>\n    <tr>\n      <th>D</th>\n      <td>54.26</td>\n    </tr>\n    <tr>\n      <th>E</th>\n      <td>44.00</td>\n    </tr>\n    <tr>\n      <th>F</th>\n      <td>20.22</td>\n    </tr>\n    <tr>\n      <th>G</th>\n      <td>16.70</td>\n    </tr>\n    <tr>\n      <th>T</th>\n      <td>35.50</td>\n    </tr>\n    <tr>\n      <th>Z</th>\n      <td>18.96</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\nohe_Cabin_augment = OneHotEncoder(categories='auto')\nfeature_array_Cabin_augment = ohe_Cabin_augment.fit_transform(df_train_split[['Cabin_augment']]).toarray()\n#feature_labels = ohe.categories_\nfeatures_Cabin_augment = pd.DataFrame(feature_array_Cabin_augment, columns=ohe_Cabin_augment.get_feature_names())\n","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_split.drop(['Cabin','Cabin_augment'], axis =1, inplace = True)\ndf_train_split = pd.concat([df_train_split,features_Cabin_augment], axis = 1)","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_split.head()","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"                                                Name   Age   Ticket     Fare  \\\n0                                   Buss, Miss. Kate  36.0    27849  13.0000   \n1                                  Toufik, Mr. Nakli  29.0     2641   7.2292   \n2                     Goodwin, Master. Harold Victor   9.0  CA 2144  46.9000   \n3                       Jacobsohn, Mr. Sidney Samuel  42.0   243847  27.0000   \n4  Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...  30.0   345773  24.1500   \n\n   Survived  x0_0  x0_1  x0_2  x0_3  x0_4  x0_5  x0_6  x1_1  x1_2  x1_3  \\\n0         1   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   \n1         0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   \n2         0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   \n3         0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   \n4         0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   \n\n   x2_female  x2_male  x3_0  x3_1  x3_2  x3_3  x3_4  x3_5  x3_8  x4_C  x4_Q  \\\n0        1.0      0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n1        0.0      1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   \n2        0.0      1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   \n3        0.0      1.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n4        1.0      0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n\n   x4_S  x0_A  x0_B  x0_C  x0_D  x0_E  x0_F  x0_G  x0_T  x0_Z  \n0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  \n1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  \n2   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  \n3   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  \n4   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Age</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Survived</th>\n      <th>x0_0</th>\n      <th>x0_1</th>\n      <th>x0_2</th>\n      <th>x0_3</th>\n      <th>x0_4</th>\n      <th>x0_5</th>\n      <th>x0_6</th>\n      <th>x1_1</th>\n      <th>x1_2</th>\n      <th>x1_3</th>\n      <th>x2_female</th>\n      <th>x2_male</th>\n      <th>x3_0</th>\n      <th>x3_1</th>\n      <th>x3_2</th>\n      <th>x3_3</th>\n      <th>x3_4</th>\n      <th>x3_5</th>\n      <th>x3_8</th>\n      <th>x4_C</th>\n      <th>x4_Q</th>\n      <th>x4_S</th>\n      <th>x0_A</th>\n      <th>x0_B</th>\n      <th>x0_C</th>\n      <th>x0_D</th>\n      <th>x0_E</th>\n      <th>x0_F</th>\n      <th>x0_G</th>\n      <th>x0_T</th>\n      <th>x0_Z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Buss, Miss. Kate</td>\n      <td>36.0</td>\n      <td>27849</td>\n      <td>13.0000</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Toufik, Mr. Nakli</td>\n      <td>29.0</td>\n      <td>2641</td>\n      <td>7.2292</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Goodwin, Master. Harold Victor</td>\n      <td>9.0</td>\n      <td>CA 2144</td>\n      <td>46.9000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Jacobsohn, Mr. Sidney Samuel</td>\n      <td>42.0</td>\n      <td>243847</td>\n      <td>27.0000</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...</td>\n      <td>30.0</td>\n      <td>345773</td>\n      <td>24.1500</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_train_split = pd.get_dummies(df_train_split, columns=['Cabin_augment'])","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_train_split.head()","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_split.drop(['Name','Ticket'], axis = 1, inplace = True)","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_split.head()","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"    Age     Fare  Survived  x0_0  x0_1  x0_2  x0_3  x0_4  x0_5  x0_6  x1_1  \\\n0  36.0  13.0000         1   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n1  29.0   7.2292         0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n2   9.0  46.9000         0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   \n3  42.0  27.0000         0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n4  30.0  24.1500         0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   \n\n   x1_2  x1_3  x2_female  x2_male  x3_0  x3_1  x3_2  x3_3  x3_4  x3_5  x3_8  \\\n0   1.0   0.0        1.0      0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   \n1   0.0   1.0        0.0      1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   \n2   0.0   1.0        0.0      1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   \n3   1.0   0.0        0.0      1.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   \n4   0.0   1.0        1.0      0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   \n\n   x4_C  x4_Q  x4_S  x0_A  x0_B  x0_C  x0_D  x0_E  x0_F  x0_G  x0_T  x0_Z  \n0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  \n1   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  \n2   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  \n3   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  \n4   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Fare</th>\n      <th>Survived</th>\n      <th>x0_0</th>\n      <th>x0_1</th>\n      <th>x0_2</th>\n      <th>x0_3</th>\n      <th>x0_4</th>\n      <th>x0_5</th>\n      <th>x0_6</th>\n      <th>x1_1</th>\n      <th>x1_2</th>\n      <th>x1_3</th>\n      <th>x2_female</th>\n      <th>x2_male</th>\n      <th>x3_0</th>\n      <th>x3_1</th>\n      <th>x3_2</th>\n      <th>x3_3</th>\n      <th>x3_4</th>\n      <th>x3_5</th>\n      <th>x3_8</th>\n      <th>x4_C</th>\n      <th>x4_Q</th>\n      <th>x4_S</th>\n      <th>x0_A</th>\n      <th>x0_B</th>\n      <th>x0_C</th>\n      <th>x0_D</th>\n      <th>x0_E</th>\n      <th>x0_F</th>\n      <th>x0_G</th>\n      <th>x0_T</th>\n      <th>x0_Z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>36.0</td>\n      <td>13.0000</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>29.0</td>\n      <td>7.2292</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9.0</td>\n      <td>46.9000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>42.0</td>\n      <td>27.0000</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>30.0</td>\n      <td>24.1500</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking that all missing values are taken care of\nprint(df_train_split.isna().sum().sum())\ndf_train_split.shape","execution_count":32,"outputs":[{"output_type":"stream","text":"0\n","name":"stdout"},{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"(643, 34)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_split_X = df_train_split.drop(['Survived'],axis = 1)\ndf_train_split_y = df_train_split[['Survived']]","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Performing Save Data Wrangling Steps on the Val/Test Data\n\n#combining the train feature/target data for EDA/Data Wrangling\ndf_val_split = pd.concat([X_val, y_val], axis = 1)\ndf_val_split.Embarked = df_val_split.Embarked.fillna('S')\ndf_val_split.drop(['PassengerId'], axis = 1, inplace = True)\n\nfeature_array = ohe.transform(df_val_split[['Parch','Pclass','Sex','SibSp','Embarked']]).toarray()\nfeatures = pd.DataFrame(feature_array, columns=ohe.get_feature_names())\ndf_val_split = df_val_split.drop(['Parch','Pclass','Sex','SibSp','Embarked'], axis = 1)\ndf_val_split = pd.concat([df_val_split.reset_index(drop=True),features.reset_index(drop=True)], axis = 1)\n\ndf_val_split['Age'] = df_val_split['Age'].apply(lambda x : median_age_train if pd.isnull(x) else x)\n\ndf_val_split.Cabin = df_val_split[['Cabin']].fillna(value= 'Z')\ndf_val_split['Cabin_augment'] = df_val_split.Cabin.apply(lambda x : x[0])\n\nfeature_array_Cabin_augment = ohe_Cabin_augment.transform(df_val_split[['Cabin_augment']]).toarray()\nfeatures_Cabin_augment = pd.DataFrame(feature_array_Cabin_augment, columns=ohe_Cabin_augment.get_feature_names())\n\ndf_val_split.drop(['Cabin','Cabin_augment'], axis =1, inplace = True)\ndf_val_split = pd.concat([df_val_split,features_Cabin_augment], axis = 1)\n\ndf_val_split.drop(['Name','Ticket'], axis = 1, inplace = True)\n\nprint(df_val_split.shape)\ndf_val_split.head()","execution_count":34,"outputs":[{"output_type":"stream","text":"(114, 34)\n","name":"stdout"},{"output_type":"execute_result","execution_count":34,"data":{"text/plain":"    Age     Fare  Survived  x0_0  x0_1  x0_2  x0_3  x0_4  x0_5  x0_6  x1_1  \\\n0  14.0  46.9000         0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   \n1  36.0  10.5000         0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n2   9.0  31.3875         0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   \n3  19.0   7.8792         1   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n4  45.0   8.0500         1   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n\n   x1_2  x1_3  x2_female  x2_male  x3_0  x3_1  x3_2  x3_3  x3_4  x3_5  x3_8  \\\n0   0.0   1.0        0.0      1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   \n1   1.0   0.0        0.0      1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   \n2   0.0   1.0        0.0      1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   \n3   0.0   1.0        1.0      0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   \n4   0.0   1.0        0.0      1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   \n\n   x4_C  x4_Q  x4_S  x0_A  x0_B  x0_C  x0_D  x0_E  x0_F  x0_G  x0_T  x0_Z  \n0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  \n1   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  \n2   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  \n3   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  \n4   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Fare</th>\n      <th>Survived</th>\n      <th>x0_0</th>\n      <th>x0_1</th>\n      <th>x0_2</th>\n      <th>x0_3</th>\n      <th>x0_4</th>\n      <th>x0_5</th>\n      <th>x0_6</th>\n      <th>x1_1</th>\n      <th>x1_2</th>\n      <th>x1_3</th>\n      <th>x2_female</th>\n      <th>x2_male</th>\n      <th>x3_0</th>\n      <th>x3_1</th>\n      <th>x3_2</th>\n      <th>x3_3</th>\n      <th>x3_4</th>\n      <th>x3_5</th>\n      <th>x3_8</th>\n      <th>x4_C</th>\n      <th>x4_Q</th>\n      <th>x4_S</th>\n      <th>x0_A</th>\n      <th>x0_B</th>\n      <th>x0_C</th>\n      <th>x0_D</th>\n      <th>x0_E</th>\n      <th>x0_F</th>\n      <th>x0_G</th>\n      <th>x0_T</th>\n      <th>x0_Z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14.0</td>\n      <td>46.9000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>36.0</td>\n      <td>10.5000</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9.0</td>\n      <td>31.3875</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>19.0</td>\n      <td>7.8792</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>45.0</td>\n      <td>8.0500</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_val_split_X = df_val_split.drop(['Survived'],axis = 1)\ndf_val_split_y = df_val_split[['Survived']]","execution_count":35,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Developement "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Baseline Model \nimport xgboost as xgb\n\neval_set = [(df_val_split_X,df_val_split_y)]\n\nmodel_xgb = xgb.XGBClassifier(learning_rate = 0.01)\nmodel_xgb.fit(df_train_split_X, df_train_split_y, early_stopping_rounds=10, eval_metric=\"error\", eval_set= eval_set,verbose = 0)","execution_count":37,"outputs":[{"output_type":"execute_result","execution_count":37,"data":{"text/plain":"XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.01, max_delta_step=0, max_depth=6,\n              min_child_weight=1, missing=nan, monotone_constraints='()',\n              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n              tree_method='exact', validate_parameters=1, verbosity=None)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\nprint(\"Training Accuracy:\", accuracy_score(model_xgb.predict(df_train_split_X),df_train_split_y))\nprint(\"Validation Accuracy:\", accuracy_score(model_xgb.predict(df_val_split_X),df_val_split_y))","execution_count":38,"outputs":[{"output_type":"stream","text":"Training Accuracy: 0.880248833592535\nValidation Accuracy: 0.7894736842105263\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding Parameter Tuning\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    \"learning_rate\": [0.1,0.05],\n    'max_depth': [2,3,4,5,6],\n    'min_child_weight': [1, 2,4,6,8,10],\n    'subsample': [0.5, 0.7, 0.9],\n    'n_estimators': [5, 30, 100, 250, 500],\n}\n\ngrid_clf = GridSearchCV(xgb.XGBClassifier() , param_grid, scoring='accuracy', cv=None)\ngrid_clf.fit(df_train_split_X, df_train_split_y , early_stopping_rounds=10 , eval_metric=\"error\", eval_set= eval_set,verbose = False)\n\nbest_parameters = grid_clf.best_params_\n\nprint('Grid Search found the following optimal parameters: ')\nfor param_name in sorted(best_parameters.keys()):\n    print('%s: %r' % (param_name, best_parameters[param_name]))\n    \nprint(\"Training Accuracy:\", accuracy_score(grid_clf.predict(df_train_split_X),df_train_split_y))\nprint(\"Validation Accuracy:\", accuracy_score(grid_clf.predict(df_val_split_X),df_val_split_y))\n","execution_count":40,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  return f(**kwargs)\n","name":"stderr"},{"output_type":"stream","text":"Grid Search found the following optimal parameters: \nlearning_rate: 0.1\nmax_depth: 4\nmin_child_weight: 4\nn_estimators: 30\nsubsample: 0.9\nTraining Accuracy: 0.8227060653188181\nValidation Accuracy: 0.7894736842105263\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\ngnb = GaussianNB()\n\ngnb.fit(df_train_split_X, df_train_split_y.values.ravel())\n\nprint(\"Training Accuracy:\", accuracy_score(gnb.predict(df_train_split_X),df_train_split_y))\nprint(\"Validation Accuracy:\", accuracy_score(gnb.predict(df_val_split_X),df_val_split_y))","execution_count":53,"outputs":[{"output_type":"stream","text":"Training Accuracy: 0.4307931570762053\nValidation Accuracy: 0.4649122807017544\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nclf_log = LogisticRegression(random_state=0, max_iter = 1000).fit(df_train_split_X, df_train_split_y.values.ravel())\n\nprint(\"Training Accuracy:\", accuracy_score(clf_log.predict(df_train_split_X),df_train_split_y))\nprint(\"Validation Accuracy:\", accuracy_score(clf_log.predict(df_val_split_X),df_val_split_y))","execution_count":52,"outputs":[{"output_type":"stream","text":"Training Accuracy: 0.8289269051321928\nValidation Accuracy: 0.7807017543859649\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Potential Next Steps / Changes to Consider\n- Potentially use K-Fold Cross validation due to small size \n- https://alexforrest.github.io/you-might-be-leaking-data-even-if-you-cross-validate.html\n- https://machinelearningmastery.com/data-preparation-without-data-leakage/"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}