{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Kaggle Titanic Machine Learning\n- source of competition: https://www.kaggle.com/c/titanic\n- Data Dictionary: https://www.kaggle.com/c/titanic/data\n- useful link for saving to GitHub: https://www.kaggle.com/questions-and-answers/72234"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Importing libraries\n%matplotlib inline\nimport numpy as np \nimport pandas as pd \nimport pandas_profiling\n\n# Setting Random Seed For Reproducibility\nimport random\nrandom.seed(123)\n\n# Displaying Max rows\npd.set_option('display.max_rows', 1000)\npd.set_option('display.max_columns', 100)\n\n# Listing Files\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":129,"outputs":[{"output_type":"stream","text":"/kaggle/input/titanic/gender_submission.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/train.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/titanic/train.csv')\ndf_test = pd.read_csv('/kaggle/input/titanic/test.csv') # for final evaluation/submission only","execution_count":130,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":131,"outputs":[{"output_type":"execute_result","execution_count":131,"data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":132,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Data Wrangling/Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating train/val/test split prior to transformations (avoid data leakage)\n\nX = df_train.drop(['Survived'],axis = 1)\ny = df_train.Survived\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.15, random_state = 3) # test set 15% train\nX_train, X_val, y_train, y_val   = train_test_split(X_train, y_train, test_size = 0.15, random_state = 3) #validation set 15% train","execution_count":133,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in [X_train,X_test,X_val]:\n    print(i.shape)","execution_count":134,"outputs":[{"output_type":"stream","text":"(643, 11)\n(134, 11)\n(114, 11)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis\n\nGeneral thoughts based on the profile below\n- PassengerId - removing due to ID variable\n- Missing values: Age, Cabin, Fare, Embarked\n- Correlations in Fare-Class-Age"},{"metadata":{"trusted":true},"cell_type":"code","source":"#combining the train feature/target data for EDA/Data Wrangling\n\ndf_train_split = pd.concat([X_train, y_train], axis = 1)\ndf_train_split.head(2)","execution_count":135,"outputs":[{"output_type":"execute_result","execution_count":135,"data":{"text/plain":"     PassengerId  Pclass               Name     Sex   Age  SibSp  Parch  \\\n387          388       2   Buss, Miss. Kate  female  36.0      0      0   \n531          532       3  Toufik, Mr. Nakli    male   NaN      0      0   \n\n    Ticket     Fare Cabin Embarked  Survived  \n387  27849  13.0000   NaN        S         1  \n531   2641   7.2292   NaN        C         0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>387</th>\n      <td>388</td>\n      <td>2</td>\n      <td>Buss, Miss. Kate</td>\n      <td>female</td>\n      <td>36.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>27849</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>531</th>\n      <td>532</td>\n      <td>3</td>\n      <td>Toufik, Mr. Nakli</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2641</td>\n      <td>7.2292</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#making use of the profile package for EDA plots/stats/...\n\nprofile = pandas_profiling.ProfileReport(df_train_split, title = \"EDA Profile Train Data Report\")","execution_count":108,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='variables', max=13.0, style=ProgressStyle(description_widâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99cfef58a72f4e6a8a5e4ffad6e8dbaa"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='correlations', max=6.0, style=ProgressStyle(description_wâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f9a3608004c4e7f97b4ad50825b80be"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='interactions [continuous]', max=36.0, style=ProgressStyleâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31a6ecf22484480ab57f70e910b90902"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='table', max=1.0, style=ProgressStyle(description_width='iâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2533a6e555e640bea456dae9c00363d5"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='missing', max=4.0, style=ProgressStyle(description_width=â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2ec6225efd64d8f9f5bdadaa7c406a8"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='warnings', max=3.0, style=ProgressStyle(description_widthâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d37cd3c348bb49a1ab9d4c752e53dfa7"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='package', max=1.0, style=ProgressStyle(description_width=â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0d9bedc85734b868e6221991a4c2b03"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='build report structure', max=1.0, style=ProgressStyle(desâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bee99cfbfade458c83dcb3d7703099be"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"profile.to_widgets()","execution_count":109,"outputs":[{"output_type":"display_data","data":{"text/plain":"Tab(children=(Tab(children=(GridBox(children=(VBox(children=(GridspecLayout(children=(HTML(value='Number of vaâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f4694e62425446f9dcff6990f1a6715"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Report generated with <a href=\"https://github.com/pandas-profiling/pandas-profiling\">pandas-profiling</a>."},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Data Wrangling and Feature Engineering\n- only on training dataset, will use a pipeline for val/test and final submission test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Missing Values Handling\nprint(df_train_split.Embarked.value_counts())\n\n#Embarked only 1 missing, fill with most common of S, C, Q (will be S)\ndf_train_split.Embarked = df_train_split.Embarked.fillna(df_train_split.Embarked.value_counts().index[0]) #using value_counts top record","execution_count":136,"outputs":[{"output_type":"stream","text":"S    475\nC    118\nQ     49\nName: Embarked, dtype: int64\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping passenger id (is an id)\ndf_train_split.drop(['PassengerId'], axis = 1, inplace = True)","execution_count":137,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\nohe = OneHotEncoder(categories='auto')\nfeature_array = ohe.fit_transform(df_train_split[['Parch','Pclass','Sex','SibSp','Embarked']]).toarray()\n#feature_labels = ohe.categories_","execution_count":138,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = pd.DataFrame(feature_array, columns=ohe.get_feature_names())\nfeatures.shape","execution_count":139,"outputs":[{"output_type":"execute_result","execution_count":139,"data":{"text/plain":"(643, 22)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_split = df_train_split.drop(['Parch','Pclass','Sex','SibSp','Embarked'], axis = 1)\n","execution_count":140,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_split = pd.concat([df_train_split,features], axis = 1)","execution_count":141,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_split.head()","execution_count":143,"outputs":[{"output_type":"execute_result","execution_count":143,"data":{"text/plain":"                                                Name   Age            Ticket  \\\n0                            Braund, Mr. Owen Harris  22.0         A/5 21171   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0          PC 17599   \n2                             Heikkinen, Miss. Laina  26.0  STON/O2. 3101282   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0            113803   \n4                           Allen, Mr. William Henry  35.0            373450   \n\n      Fare Cabin  Survived  x0_0  x0_1  x0_2  x0_3  x0_4  x0_5  x0_6  x1_1  \\\n0   7.2500   NaN       0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n1  71.2833   C85       1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n2   7.9250   NaN       1.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   \n3  53.1000  C123       1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n4   8.0500   NaN       0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   \n\n   x1_2  x1_3  x2_female  x2_male  x3_0  x3_1  x3_2  x3_3  x3_4  x3_5  x3_8  \\\n0   1.0   0.0        1.0      0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   \n1   0.0   1.0        0.0      1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   \n2   0.0   1.0        0.0      1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   \n3   1.0   0.0        0.0      1.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   \n4   0.0   1.0        1.0      0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   \n\n   x4_C  x4_Q  x4_S  \n0   0.0   0.0   1.0  \n1   1.0   0.0   0.0  \n2   0.0   0.0   1.0  \n3   0.0   0.0   1.0  \n4   0.0   0.0   1.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Age</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Survived</th>\n      <th>x0_0</th>\n      <th>x0_1</th>\n      <th>x0_2</th>\n      <th>x0_3</th>\n      <th>x0_4</th>\n      <th>x0_5</th>\n      <th>x0_6</th>\n      <th>x1_1</th>\n      <th>x1_2</th>\n      <th>x1_3</th>\n      <th>x2_female</th>\n      <th>x2_male</th>\n      <th>x3_0</th>\n      <th>x3_1</th>\n      <th>x3_2</th>\n      <th>x3_3</th>\n      <th>x3_4</th>\n      <th>x3_5</th>\n      <th>x3_8</th>\n      <th>x4_C</th>\n      <th>x4_Q</th>\n      <th>x4_S</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>22.0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>38.0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>26.0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>35.0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Allen, Mr. William Henry</td>\n      <td>35.0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Encoding categorical features (will be used to impute Age/Cabin missing values as possible)\n\n# df_train_split = pd.get_dummies(df_train_split, columns=['Parch','Pclass','Sex','SibSp','Embarked'])\n# df_train_split","execution_count":144,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encoding the Age Missing Values that are 'S' with the training data median Age \nmedian_age_train = df_train_split.Age.median()\ndf_train_split['Age'] = df_train_split['Age'].apply(lambda x : median_age_train if pd.isnull(x) else x)\ndf_train_split.Age.isna().sum()","execution_count":145,"outputs":[{"output_type":"execute_result","execution_count":145,"data":{"text/plain":"0"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Cabin Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"#INPROGRESS #Missing Values Cabin - taking the initial value\ndf_train_split.Cabin = df_train_split[['Cabin']].fillna(value= 'Z')\ndf_train_split['Cabin_augment'] = df_train_split.Cabin.apply(lambda x : x[0]) # augmenting dataset, only want the first letter (numbers not matter)\ndf_train_split.Cabin_augment.value_counts()","execution_count":146,"outputs":[{"output_type":"execute_result","execution_count":146,"data":{"text/plain":"Z    681\nC     44\nB     33\nD     26\nE     24\nA     12\nF     11\nG      1\nT      1\nName: Cabin_augment, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_split[['Cabin_augment','Fare']].groupby(['Cabin_augment']).mean().round(2)","execution_count":147,"outputs":[{"output_type":"execute_result","execution_count":147,"data":{"text/plain":"                 Fare\nCabin_augment        \nA               39.35\nB              118.79\nC               91.22\nD               54.26\nE               44.00\nF               20.22\nG               16.70\nT               35.50\nZ               18.96","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Fare</th>\n    </tr>\n    <tr>\n      <th>Cabin_augment</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>A</th>\n      <td>39.35</td>\n    </tr>\n    <tr>\n      <th>B</th>\n      <td>118.79</td>\n    </tr>\n    <tr>\n      <th>C</th>\n      <td>91.22</td>\n    </tr>\n    <tr>\n      <th>D</th>\n      <td>54.26</td>\n    </tr>\n    <tr>\n      <th>E</th>\n      <td>44.00</td>\n    </tr>\n    <tr>\n      <th>F</th>\n      <td>20.22</td>\n    </tr>\n    <tr>\n      <th>G</th>\n      <td>16.70</td>\n    </tr>\n    <tr>\n      <th>T</th>\n      <td>35.50</td>\n    </tr>\n    <tr>\n      <th>Z</th>\n      <td>18.96</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\nohe_Cabin_augment = OneHotEncoder(categories='auto')\nfeature_array_Cabin_augment = ohe_Cabin_augment.fit_transform(df_train_split[['Cabin_augment']]).toarray()\n#feature_labels = ohe.categories_\nfeatures_Cabin_augment = pd.DataFrame(feature_array_Cabin_augment, columns=ohe_Cabin_augment.get_feature_names())\n","execution_count":148,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_split.drop(['Cabin'], axis =1, inplace = True)\ndf_train_split = pd.concat([df_train_split,features_Cabin_augment], axis = 1)","execution_count":149,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_split.head()","execution_count":150,"outputs":[{"output_type":"execute_result","execution_count":150,"data":{"text/plain":"                                                Name   Age            Ticket  \\\n0                            Braund, Mr. Owen Harris  22.0         A/5 21171   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0          PC 17599   \n2                             Heikkinen, Miss. Laina  26.0  STON/O2. 3101282   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0            113803   \n4                           Allen, Mr. William Henry  35.0            373450   \n\n      Fare  Survived  x0_0  x0_1  x0_2  x0_3  x0_4  x0_5  x0_6  x1_1  x1_2  \\\n0   7.2500       0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   \n1  71.2833       1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n2   7.9250       1.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   \n3  53.1000       1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   \n4   8.0500       0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n\n   x1_3  x2_female  x2_male  x3_0  x3_1  x3_2  x3_3  x3_4  x3_5  x3_8  x4_C  \\\n0   0.0        1.0      0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n1   1.0        0.0      1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   \n2   1.0        0.0      1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   \n3   0.0        0.0      1.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   \n4   1.0        1.0      0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   \n\n   x4_Q  x4_S Cabin_augment  x0_A  x0_B  x0_C  x0_D  x0_E  x0_F  x0_G  x0_T  \\\n0   0.0   1.0             Z   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n1   0.0   0.0             C   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   \n2   0.0   1.0             Z   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n3   0.0   1.0             C   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   \n4   0.0   1.0             Z   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n\n   x0_Z  \n0   1.0  \n1   0.0  \n2   1.0  \n3   0.0  \n4   1.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Age</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Survived</th>\n      <th>x0_0</th>\n      <th>x0_1</th>\n      <th>x0_2</th>\n      <th>x0_3</th>\n      <th>x0_4</th>\n      <th>x0_5</th>\n      <th>x0_6</th>\n      <th>x1_1</th>\n      <th>x1_2</th>\n      <th>x1_3</th>\n      <th>x2_female</th>\n      <th>x2_male</th>\n      <th>x3_0</th>\n      <th>x3_1</th>\n      <th>x3_2</th>\n      <th>x3_3</th>\n      <th>x3_4</th>\n      <th>x3_5</th>\n      <th>x3_8</th>\n      <th>x4_C</th>\n      <th>x4_Q</th>\n      <th>x4_S</th>\n      <th>Cabin_augment</th>\n      <th>x0_A</th>\n      <th>x0_B</th>\n      <th>x0_C</th>\n      <th>x0_D</th>\n      <th>x0_E</th>\n      <th>x0_F</th>\n      <th>x0_G</th>\n      <th>x0_T</th>\n      <th>x0_Z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>22.0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>Z</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>38.0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>C</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>26.0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>Z</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>35.0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>C</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Allen, Mr. William Henry</td>\n      <td>35.0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>Z</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_train_split = pd.get_dummies(df_train_split, columns=['Cabin_augment'])","execution_count":151,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_train_split.head()","execution_count":152,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_split.drop(['Name','Ticket'], axis = 1, inplace = True)","execution_count":153,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"\"['Cabin'] not found in axis\"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-153-de254572e1e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train_split\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Ticket'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Cabin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4172\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4173\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4174\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4175\u001b[0m         )\n\u001b[1;32m   4176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3885\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3886\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3887\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3889\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3919\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3920\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3921\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3922\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5283\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5284\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5285\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"['Cabin'] not found in axis\""]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_split.head()","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"      Age     Fare  Survived  Parch_0  Parch_1  Parch_2  Parch_3  Parch_4  \\\n387  36.0  13.0000         1        1        0        0        0        0   \n531  29.0   7.2292         0        1        0        0        0        0   \n480   9.0  46.9000         0        0        0        1        0        0   \n217  42.0  27.0000         0        1        0        0        0        0   \n799  30.0  24.1500         0        0        1        0        0        0   \n\n     Parch_5  Parch_6  Pclass_1  Pclass_2  Pclass_3  Sex_female  Sex_male  \\\n387        0        0         0         1         0           1         0   \n531        0        0         0         0         1           0         1   \n480        0        0         0         0         1           0         1   \n217        0        0         0         1         0           0         1   \n799        0        0         0         0         1           1         0   \n\n     SibSp_0  SibSp_1  SibSp_2  SibSp_3  SibSp_4  SibSp_5  SibSp_8  \\\n387        1        0        0        0        0        0        0   \n531        1        0        0        0        0        0        0   \n480        0        0        0        0        0        1        0   \n217        0        1        0        0        0        0        0   \n799        0        1        0        0        0        0        0   \n\n     Embarked_C  Embarked_Q  Embarked_S  Cabin_augment_A  Cabin_augment_B  \\\n387           0           0           1                0                0   \n531           1           0           0                0                0   \n480           0           0           1                0                0   \n217           0           0           1                0                0   \n799           0           0           1                0                0   \n\n     Cabin_augment_C  Cabin_augment_D  Cabin_augment_E  Cabin_augment_F  \\\n387                0                0                0                0   \n531                0                0                0                0   \n480                0                0                0                0   \n217                0                0                0                0   \n799                0                0                0                0   \n\n     Cabin_augment_G  Cabin_augment_T  Cabin_augment_Z  \n387                0                0                1  \n531                0                0                1  \n480                0                0                1  \n217                0                0                1  \n799                0                0                1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Fare</th>\n      <th>Survived</th>\n      <th>Parch_0</th>\n      <th>Parch_1</th>\n      <th>Parch_2</th>\n      <th>Parch_3</th>\n      <th>Parch_4</th>\n      <th>Parch_5</th>\n      <th>Parch_6</th>\n      <th>Pclass_1</th>\n      <th>Pclass_2</th>\n      <th>Pclass_3</th>\n      <th>Sex_female</th>\n      <th>Sex_male</th>\n      <th>SibSp_0</th>\n      <th>SibSp_1</th>\n      <th>SibSp_2</th>\n      <th>SibSp_3</th>\n      <th>SibSp_4</th>\n      <th>SibSp_5</th>\n      <th>SibSp_8</th>\n      <th>Embarked_C</th>\n      <th>Embarked_Q</th>\n      <th>Embarked_S</th>\n      <th>Cabin_augment_A</th>\n      <th>Cabin_augment_B</th>\n      <th>Cabin_augment_C</th>\n      <th>Cabin_augment_D</th>\n      <th>Cabin_augment_E</th>\n      <th>Cabin_augment_F</th>\n      <th>Cabin_augment_G</th>\n      <th>Cabin_augment_T</th>\n      <th>Cabin_augment_Z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>387</th>\n      <td>36.0</td>\n      <td>13.0000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>531</th>\n      <td>29.0</td>\n      <td>7.2292</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>480</th>\n      <td>9.0</td>\n      <td>46.9000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>217</th>\n      <td>42.0</td>\n      <td>27.0000</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>799</th>\n      <td>30.0</td>\n      <td>24.1500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking that all missing values are taken care of\ndf_train_split.isna().sum().sum()","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"0"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_split_X = df_train_split.drop(['Survived'],axis = 1)\ndf_train_split_y = df_train_split[['Survived']]","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Performing Save Data Wrangling Steps on the Val/Test Data\n\n#combining the train feature/target data for EDA/Data Wrangling\n\ndf_val_split = pd.concat([X_val, y_val], axis = 1)\ndf_val_split.Embarked = df_val_split.Embarked.fillna('S') #using value_counts top record df_val_split.Embarked.value_counts()\ndf_val_split.drop(['PassengerId'], axis = 1, inplace = True)\ndf_val_split = pd.get_dummies(df_val_split, columns=['Parch','Pclass','Sex','SibSp','Embarked'])\ndf_val_split['Age'] = df_val_split['Age'].apply(lambda x : median_age_train if pd.isnull(x) else x)\n\ndf_val_split.Cabin = df_val_split[['Cabin']].fillna(value= 'Z')\ndf_val_split['Cabin_augment'] = df_val_split.Cabin.apply(lambda x : x[0])\n\ndf_val_split = pd.get_dummies(df_val_split, columns=['Cabin_augment'])\ndf_val_split.drop(['Name','Ticket','Cabin'], axis = 1, inplace = True)\n\nprint(df_val_split.isna().sum().sum())\ndf_val_split.head()","execution_count":57,"outputs":[{"output_type":"stream","text":"0\n","name":"stdout"},{"output_type":"execute_result","execution_count":57,"data":{"text/plain":"      Age     Fare  Survived  Parch_0  Parch_1  Parch_2  Parch_4  Parch_5  \\\n683  14.0  46.9000         0        0        0        1        0        0   \n265  36.0  10.5000         0        1        0        0        0        0   \n182   9.0  31.3875         0        0        0        1        0        0   \n44   19.0   7.8792         1        1        0        0        0        0   \n338  45.0   8.0500         1        1        0        0        0        0   \n\n     Pclass_1  Pclass_2  Pclass_3  Sex_female  Sex_male  SibSp_0  SibSp_1  \\\n683         0         0         1           0         1        0        0   \n265         0         1         0           0         1        1        0   \n182         0         0         1           0         1        0        0   \n44          0         0         1           1         0        1        0   \n338         0         0         1           0         1        1        0   \n\n     SibSp_2  SibSp_3  SibSp_4  SibSp_5  SibSp_8  Embarked_C  Embarked_Q  \\\n683        0        0        0        1        0           0           0   \n265        0        0        0        0        0           0           0   \n182        0        0        1        0        0           0           0   \n44         0        0        0        0        0           0           1   \n338        0        0        0        0        0           0           0   \n\n     Embarked_S  Cabin_augment_A  Cabin_augment_B  Cabin_augment_C  \\\n683           1                0                0                0   \n265           1                0                0                0   \n182           1                0                0                0   \n44            0                0                0                0   \n338           1                0                0                0   \n\n     Cabin_augment_D  Cabin_augment_E  Cabin_augment_F  Cabin_augment_G  \\\n683                0                0                0                0   \n265                0                0                0                0   \n182                0                0                0                0   \n44                 0                0                0                0   \n338                0                0                0                0   \n\n     Cabin_augment_Z  \n683                1  \n265                1  \n182                1  \n44                 1  \n338                1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Fare</th>\n      <th>Survived</th>\n      <th>Parch_0</th>\n      <th>Parch_1</th>\n      <th>Parch_2</th>\n      <th>Parch_4</th>\n      <th>Parch_5</th>\n      <th>Pclass_1</th>\n      <th>Pclass_2</th>\n      <th>Pclass_3</th>\n      <th>Sex_female</th>\n      <th>Sex_male</th>\n      <th>SibSp_0</th>\n      <th>SibSp_1</th>\n      <th>SibSp_2</th>\n      <th>SibSp_3</th>\n      <th>SibSp_4</th>\n      <th>SibSp_5</th>\n      <th>SibSp_8</th>\n      <th>Embarked_C</th>\n      <th>Embarked_Q</th>\n      <th>Embarked_S</th>\n      <th>Cabin_augment_A</th>\n      <th>Cabin_augment_B</th>\n      <th>Cabin_augment_C</th>\n      <th>Cabin_augment_D</th>\n      <th>Cabin_augment_E</th>\n      <th>Cabin_augment_F</th>\n      <th>Cabin_augment_G</th>\n      <th>Cabin_augment_Z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>683</th>\n      <td>14.0</td>\n      <td>46.9000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>265</th>\n      <td>36.0</td>\n      <td>10.5000</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>182</th>\n      <td>9.0</td>\n      <td>31.3875</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>19.0</td>\n      <td>7.8792</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>338</th>\n      <td>45.0</td>\n      <td>8.0500</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_val_split_X = df_val_split.drop(['Survived'],axis = 1)\ndf_val_split_y = df_val_split[['Survived']]","execution_count":58,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Developement "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Baseline Model \nimport xgboost as xgb\n\nmodel_xgb = xgb.XGBClassifier(learning_rate = 0.01)\nmodel_xgb.fit(df_train_split_X, df_train_split_y)","execution_count":60,"outputs":[{"output_type":"execute_result","execution_count":60,"data":{"text/plain":"XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.01, max_delta_step=0, max_depth=6,\n              min_child_weight=1, missing=nan, monotone_constraints='()',\n              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n              tree_method='exact', validate_parameters=1, verbosity=None)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\nprint(\"Training Accuracy:\", accuracy_score(model_xgb.predict(df_train_split_X),df_train_split_y))\nprint(\"Validation Accuracy:\", accuracy_score(model_xgb.predict(df_val_split_X),df_val_split_y))","execution_count":63,"outputs":[{"output_type":"stream","text":"Training Accuracy: 0.8880248833592534\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(model_xgb.predict(df_val_split_X),df_val_split_y)","execution_count":64,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"feature_names mismatch: ['Age', 'Fare', 'Parch_0', 'Parch_1', 'Parch_2', 'Parch_3', 'Parch_4', 'Parch_5', 'Parch_6', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male', 'SibSp_0', 'SibSp_1', 'SibSp_2', 'SibSp_3', 'SibSp_4', 'SibSp_5', 'SibSp_8', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Cabin_augment_A', 'Cabin_augment_B', 'Cabin_augment_C', 'Cabin_augment_D', 'Cabin_augment_E', 'Cabin_augment_F', 'Cabin_augment_G', 'Cabin_augment_T', 'Cabin_augment_Z'] ['Age', 'Fare', 'Parch_0', 'Parch_1', 'Parch_2', 'Parch_4', 'Parch_5', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male', 'SibSp_0', 'SibSp_1', 'SibSp_2', 'SibSp_3', 'SibSp_4', 'SibSp_5', 'SibSp_8', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Cabin_augment_A', 'Cabin_augment_B', 'Cabin_augment_C', 'Cabin_augment_D', 'Cabin_augment_E', 'Cabin_augment_F', 'Cabin_augment_G', 'Cabin_augment_Z']\nexpected Cabin_augment_T, Parch_6, Parch_3 in input data","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-64-f4c304d610a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_xgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_val_split_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_val_split_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, validate_features, base_margin)\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m             validate_features=validate_features)\n\u001b[0m\u001b[1;32m    899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;31m# If output_margin is active, simply return the scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training)\u001b[0m\n\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1935\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[0;32m-> 1936\u001b[0;31m                                             data.feature_names))\n\u001b[0m\u001b[1;32m   1937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1938\u001b[0m     def get_split_value_histogram(self, feature, fmap='', bins=None,\n","\u001b[0;31mValueError\u001b[0m: feature_names mismatch: ['Age', 'Fare', 'Parch_0', 'Parch_1', 'Parch_2', 'Parch_3', 'Parch_4', 'Parch_5', 'Parch_6', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male', 'SibSp_0', 'SibSp_1', 'SibSp_2', 'SibSp_3', 'SibSp_4', 'SibSp_5', 'SibSp_8', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Cabin_augment_A', 'Cabin_augment_B', 'Cabin_augment_C', 'Cabin_augment_D', 'Cabin_augment_E', 'Cabin_augment_F', 'Cabin_augment_G', 'Cabin_augment_T', 'Cabin_augment_Z'] ['Age', 'Fare', 'Parch_0', 'Parch_1', 'Parch_2', 'Parch_4', 'Parch_5', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male', 'SibSp_0', 'SibSp_1', 'SibSp_2', 'SibSp_3', 'SibSp_4', 'SibSp_5', 'SibSp_8', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Cabin_augment_A', 'Cabin_augment_B', 'Cabin_augment_C', 'Cabin_augment_D', 'Cabin_augment_E', 'Cabin_augment_F', 'Cabin_augment_G', 'Cabin_augment_Z']\nexpected Cabin_augment_T, Parch_6, Parch_3 in input data"]}]},{"metadata":{},"cell_type":"markdown","source":"# Potential Next Steps / Changes to Consider\n- Potentially use K-Fold Cross validation due to small size \n- https://alexforrest.github.io/you-might-be-leaking-data-even-if-you-cross-validate.html\n- https://machinelearningmastery.com/data-preparation-without-data-leakage/"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Based on the values of S (missing) compared to the distribution, should predict which are in cabins as well\n# df_train_split[['Cabin_aug','Fare']][df_train_split['Cabin_aug'].str.contains(\"S\")].hist(bins=50) \n\n# df_train_split['Cabin_aug'] = df_train_split['Cabin_aug'].apply(lambda x: None if x == 'S' else x) #setting to Nan\n\n# df_train_split.head(5)\n# test = df_train_split[['Cabin','Cabin_aug']]\n# test\n\n# test[\"Cabin_aug_code\"] = test[\"Cabin_aug\"].astype('category')\n# test[\"Cabin_aug_code\"] = test[\"Cabin_aug_code\"].cat.codes\n# test[\"Cabin_aug_code\"] = test[\"Cabin_aug_code\"].apply(lambda row: np.nan if row == -1 else row)\n# test.head(10)\n\n# df_train_split.drop(['Name','Ticket', 'Cabin'], axis =1).isna().sum()\n\n# df_knn = pd.concat([df_train_split['Fare'],test['Cabin_aug_code']], axis = 1)\n# df_knn.head(20)\n\n# # in progress \n# from sklearn.impute import KNNImputer # applying https://chrisalbon.com/machine_learning/preprocessing_structured_data/imputing_missing_class_labels_using_k-nearest_neighbors/\n\n# imputer = KNNImputer(n_neighbors= 3)\n# df_filled = imputer.fit_transform(df_knn)\n# pd.DataFrame(df_filled)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}